<h1>CS4619 Assignment, 2023</h1>
<p>
    In everyday life, we may need to separate the men from the boys, the wheat from the chaff, or the sheep from the
    goats. Hence, in this assessment, you will build an image classifier for images of your choosing. Don't use
    cats/dogs; use something else - you choose. But only use two or three classes.
</p>
<ol>
    <!-- <li>I have made available a program called <code>download_images.py</code> on Canvas. Use it to create your dataset.
        <p>To install:</p>
        <ul>
            <li>Remember to activate your virtual environment first.</li>
            <li>Then install an extra library as follows:
                <pre>
$ pip install git+https://github.com/Joeclinton1/google-images-download.git</pre>
            </li>
        </ul>
        <p>To run, type (e.g.):</p>
        <pre>
$ python3 download_images.py 100 cat dog</pre>
        <p>
            You won't be allowed a number bigger than 100. And some images may fail to download, so you may end up with
            fewer than 100.
        </p>
        <p>It places the images into a folder called <code>downloads</code>.</p>
    </li> -->
    <li>Create a folder called <code>images</code>. Inside the folder, create subfolders, one per class. For example, a folder called <code>cat</code> and another called <code>dog</code>.</li>
    <li>Obtain about 100 JPG images of each class and store them in the subfolders. How? One way is as follows:
	<ul>
	    <li>In Chrome, install the Imageye extension.</li>
	    <li>In Chrome, do a Google image search for each class. E.g. first, an image search for "cat" and, later, an image search for "dog".</li>
            <li>Run the Imageye extension. It will allow you to select which images you wish to download. You can click on <i>Tools</i> to make the menu bar appear; then you can filter by <i>Size</i> (e.g. choose just the medium and large ones, to avoid downloading thumbnails) and by <i>Type</i> (e.g. choose just JPGs). Having applied these filters, you then click on <i>Select all</i> and then <i>Download</i>.</li>
        </ul>
    </li>
    <li>Clean your dataset.
        <p>Some ideas for doing this:</p>
        <ul>
            <li>On a Mac, make sure you don't have any of those stupid .DS files or __MACOS folders.</li>
            <li>Manually delete any of the downloaded images that are not JPGs.</li>
            <li>Scan through the images manually and delete any that you think are not great examples. In my case, I would delete images that aren't good examples of cats or dogs.</li>
            <li>Corrupted exif values may cause problems during training. Clean them using ExifTool by Phil Harvey.
                <p>To install:</p>
                <ul>
                    <li>Download it from https://github.com/exiftool/exiftool</li>
                    <li>Unzip it.</li>
                </ul>
                <p>To run it:</p>
                <ul>
                    <li>Type:
                        <pre>
$ ./exiftool-master/exiftool -r -all= -ext JPG -ext JPEG ./images</pre>
                    </li>
                    <li>Look at the messages it spews out. If it complains about any of the images, then manually delete
                        those images from your dataset.
                    </li>
                    <li>ExifTool saves copies of the original images. Delete them by typing:
                        <pre>
$ find ./images -type f -name '*jp*g_original*' -delete</pre>
                    </li>
                </ul>
            </li>
        </ul>
    </li>
    <li>If necessary, either supplement your dataset (i.e. manually download a few extra images to compensate for the ones that didn't download
        and the ones that you deleted) or prune your dataset (i.e. delete some). When you finish you should have 100 images of each class.
    </li>
    <li>
        I have made available a program called <code>partition_images.py</code> on Canvas. Use it to split your dataset
        into three.
        <p>To install:</p>
        <ul>
            <li>Remember to activate your virtual environment first.</li>
            <li>Then install an extra library as follows:
                <pre>
$ pip install split-folders</pre>
        </ul>
        <p>To run, type (e.g.):</p>
        <pre>
$ python3 partition_images.py images 0.5 0.25</pre>
        <p>In this CA, I recommend a 50%-25%-25% split, as above.</p>
        <p>It creates three new folders: <code>train</code>, <code>val</code> and <code>test</code>.</p>
        <p>Afterwards, when you're sure you're done, delete the <code>images</code> folder (or move it somewhere). You can also de-install the Chrome extension.
        </p>
    <li>
        Create a Jupyter notebook called <code>ai2_training.ipynb</code>. In this Jupyter notebook, use <b>transfer
        learning</b> to build
        one or more neural network classifiers for your dataset. Your different classifiers may differ in their
        architectures (i.e. their layers), their learning rates, their use of data augmentation, and so on. (Of course,
        it is better if one classifier is motivated by failings of the previous one, e.g. if the previous one overfits,
        then the next one can try to remedy the overfitting.) Make sure your notebook includes markdown cells to explain
        what you are doing/why you are doing it/how you are doing it/etc. In the grading, this is just as important as
        the code.
        <p>
            The final cell of your notebook should save your best classifier to a file. If your best model is called
            <code>best_network</code>, for example, then the last cell of your notebook will contain the following:
        </p>
        <pre>
best_network.save("best_network.h5")</pre>
    </li>
    <li>
        Create a folder called <code>examples</code>. Into this folder, place up to 6 images. They might be copies of
        test set
        images; or they might be new images that you've downloaded from the web or that you've taken yourself; or a
        mixture. Either way, they should be carefully selected for use in step 8.
    </li>
    <li>
        Create a Jupyter notebook called <code>ai2_demo.ipynb</code>. In this Jupyter notebook, use the images that you
        selected in
        step 7 to highlight some strengths and weaknesses of the classifier that you saved in step 6. Again use markdown
        cells to give me some narrative: why do you think it gets things right/why do you think it gets things
        wrong/etc.
        <p>
            Obviously one of the earliest cells of this notebook will need to load the classifier:
        </p>
        <pre>
best_network = load_model("best_network.h5")</pre>
        <p>
            And another will need to load the images from the <code>examples</code> folder, e.g.:
        </p>
        <pre>
path = "examples"
pathnames = [os.path.join(path, filename) for filename in sorted(os.listdir(path))]

imgs = [load_img(img_path, target_size=(224, 224)) for img_path in pathnames]
for img in imgs:
    plt.figure()
    plt.imshow(img)</pre>
    </li>
    <li>
        On completion, you should have a folder that contains the following files:
        <ul>
            <li><code>ai2_training.ipynb</code></li>
            <li><code>ai2_demo.ipynb</code></li>
            <li><code>best_network.h5</code></li>
        </ul>
        <p>and the following folders:</p>
        <ul>
            <li><code>train</code></li>
            <li><code>val</code></li>
            <li><code>test</code></li>
            <li><code>examples</code></li>
        </ul>
        and nothing else.
        <p>Zip this folder.</p>
        <p>
            Before <b>1pm on Friday 3rd February 2023</b>, submit your zip file using Canvas.
        </p>
    </li>
</ol>
<p>Notes:</p>
<ul>
    <li>
        You may use the Python libraries that I advised you to install at the start of the CS4618 module. If you
        want to install additional modules, they must be ones that can be installed using pip and you must list them
        in a cell at the start of your notebook(s).
    </li>
    <li>
        All other code should be included in your notebook. No other files can be submitted.
    </li>
    <li>
        I shall interrupt each of your notebooks if they haven't completed after 30 minutes on Google Colab using a
        GPU. Thirty minutes is an enormously generous limit. Do not feel compelled to fill 30 minutes. Thirty
        minutes of mindless experiments will get a lower grade than a faster piece of insightful work. You can
        comment-out things that you tried but which proved less fruitful.
    </li>
    <li>
        You may borrow freely from the lecture handouts but otherwise the work must be your own. If you borrow
        snippets of code from elsewhere on the web, include a citation to the original source.
    </li>
    <li>
        The work must be your own. All parties to collusion will be penalized; plagiarism (both deliberate and
        inadvertent) will meet with severe penalties, which may include exclusion from the University, as will
        fabrication and falsification of results. You may be called to discuss your submission with me and this will
        inform the grading, any penalties and any disciplinary actions.
    </li>
    <li>
        Late submissions are not permitted.
    </li>
    <li>
        To obtain higher grades, everything should be well-reasoned.
    </li>
    <li>
        To obtain higher grades, you should attempt to 'push the envelope' - go beyond the bog-standard stuff from
        the lectures. E.g. do not expect a high grade if all you do is copy from lecture 22 of AI1.
    </li>
    <li>
        Do not get stressed if the things you try do not improve the accuracy. The key to a good grade is to show me
        all the interesting things that you tried plus your reasoning.
    </li>
</ul>
<p>
    And, to repeat: work on your own; do not share ideas or code; don't let others look at your solution. Everyone
    will have a unique solution.
</p>
<p>G'luck,</p>
<p>Derek</p>